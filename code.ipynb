{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import Input, Model, initializers, regularizers, models\nfrom tensorflow.keras.layers import Layer, Conv2D, Conv2DTranspose, GlobalAveragePooling2D, AveragePooling2D, MaxPool2D, UpSampling2D,\\\n                                    BatchNormalization, Activation, Flatten, Dense, Input,\\\n                                    Add, Multiply, Concatenate, concatenate, Softmax\nimport pathlib\nfrom datetime import datetime\nfrom matplotlib import pyplot as plt\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.python.keras.models import load_model\nfrom tensorflow.python.keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.activations import softmax\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:14:50.980565Z","iopub.execute_input":"2021-09-29T10:14:50.981066Z","iopub.status.idle":"2021-09-29T10:14:55.60216Z","shell.execute_reply.started":"2021-09-29T10:14:50.980986Z","shell.execute_reply":"2021-09-29T10:14:55.601256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\npermet de déterminer si l'on doit entrainer le modèle de 0 même si ses sauvegardes sont présentes\nou si l'on doit charger le modèle et entrainer depuis son dernier point de sauvegarde s'il existe déjà\n\"\"\"\ntrain_from_zero = True\n\n\"\"\"\npermet de choisir le dataset. Si sa valeur est true alors le dataset contenu dans data sera utilisé\nsinon celui contenu dans large_data\n\"\"\"\nuse_small_dataset = True\n\nif use_small_dataset:\n    images_path = \"/kaggle/input/flickr8k/Images\"\n    captions_path = \"/kaggle/input/flickr8k/captions.txt\"\n\nimg_size = (256, 256)\n\n\nbatch_size = 16\n# utile pour le chargement du dataset. shuffle_size <= batch_size\nshuffle_size = 16\n\n# permet de définir la fréquence (en itérations) de sauvegarde du modèle.\nsave_freq = 20\nepochs = 130\n\n# permet de définir le nombre de pages sur lequel on veut afficher les images présentant les données originales et\n# prédites\nnb_pages = 5\n# permet de définir le nombre d'images par page\nnb_imgs_displayed = 5","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:14:55.606969Z","iopub.execute_input":"2021-09-29T10:14:55.607313Z","iopub.status.idle":"2021-09-29T10:14:55.617675Z","shell.execute_reply.started":"2021-09-29T10:14:55.607277Z","shell.execute_reply":"2021-09-29T10:14:55.616949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_data():\n    \"\"\"\n    renvoie 3 datasets correspondant à train/test/val\n    :return:\n    \"\"\"\n    # Load the dataset\n    images = retrieve_images(captions_path)\n\n    # Split the dataset into training and validation sets\n    train_data, test_data, valid_data = train_test_val_split(images)\n    print(\"Number of training samples: \", len(train_data))\n    print(\"Number of test samples: \", len(test_data))\n    print(\"Number of validation samples: \", len(valid_data))\n\n    # Pass the list of images and the list of corresponding captions\n    train_dataset = make_dataset(train_data)\n    valid_dataset = make_dataset(valid_data)\n\n    test_dataset = (tf.convert_to_tensor([create_noisy_image(img) for img in test_data]), tf.convert_to_tensor([create_clean_image(img) for img in test_data]))\n\n    return train_dataset, valid_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:14:55.621744Z","iopub.execute_input":"2021-09-29T10:14:55.62401Z","iopub.status.idle":"2021-09-29T10:14:55.633501Z","shell.execute_reply.started":"2021-09-29T10:14:55.623976Z","shell.execute_reply":"2021-09-29T10:14:55.632863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def retrieve_images(filename):\n    \"\"\"\n    Reads the FlickR Dataset and returns a list with all the images inside\n    :param filename:\n    :return: list of image names\n    \"\"\"\n\n    images = set()\n\n    if use_small_dataset:\n        with open(filename) as caption_file:\n            caption_data = caption_file.readlines()\n\n            for line in caption_data:\n                line = line.rstrip(\"\\n\")\n                # Image name and captions are separated using a comma\n                img_name = line.split(\",\")[0]\n\n                img_name = os.path.join(images_path, img_name.strip())\n\n                if img_name.endswith(\"jpg\"):\n                    images.add(img_name)\n    else:\n        df = pd.read_csv(filename, sep=\"|\")\n\n        for index, row in df.iterrows():\n            img_name = row[\"image_name\"]\n            img_name = os.path.join(images_path, img_name.strip())\n\n            if img_name.endswith(\"jpg\"):\n                images.add(img_name)\n\n    print(\"Nb Images: {}\".format(len(images)))\n    return list(images)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:14:55.638436Z","iopub.execute_input":"2021-09-29T10:14:55.640751Z","iopub.status.idle":"2021-09-29T10:14:55.652278Z","shell.execute_reply.started":"2021-09-29T10:14:55.640718Z","shell.execute_reply":"2021-09-29T10:14:55.651592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_image(img_path, size=img_size):\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, size)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:14:55.656275Z","iopub.execute_input":"2021-09-29T10:14:55.658422Z","iopub.status.idle":"2021-09-29T10:14:55.664982Z","shell.execute_reply.started":"2021-09-29T10:14:55.658389Z","shell.execute_reply":"2021-09-29T10:14:55.664338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_noise(array):\n    \"\"\"\n        Adds random noise to each image in the supplied array.\n    \"\"\"\n\n    noise_factor = 75\n    noisy_array = array + noise_factor * tf.random.normal(tf.shape(array), mean=0.0, stddev=1.0, seed=1)\n\n    return tf.clip_by_value(noisy_array, 0, 255.0)\n\n\ndef create_noisy_image(img_path, size=img_size):\n    return create_noise(read_image(img_path, size)) / 255\n\ndef create_clean_image(img_path, size=img_size):\n    return read_image(img_path, size) /255\n","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:14:55.668969Z","iopub.execute_input":"2021-09-29T10:14:55.671434Z","iopub.status.idle":"2021-09-29T10:14:55.680638Z","shell.execute_reply.started":"2021-09-29T10:14:55.6714Z","shell.execute_reply":"2021-09-29T10:14:55.679853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_val_split(caption_data, test_frac=0.1, val_frac=0.1, shuffle=True):\n    \"\"\"\n\n    :param caption_data:\n    :param test_frac:\n    :param val_frac:\n    :param shuffle:\n    :return: train_data, test_data, val_data\n    \"\"\"\n\n    # 1. Get the list of all image names\n    all_images = caption_data\n\n    # 2. Shuffle if necessary\n    if shuffle:\n        np.random.shuffle(all_images)\n\n    # 3. Split\n    test_size = int(len(caption_data) * test_frac)\n    val_size = int(len(caption_data) * val_frac)\n\n    test_data = all_images[:test_size]\n    val_data = all_images[test_size:test_size + val_size]\n    train_data = all_images[test_size + val_size:]\n\n    return train_data, test_data, val_data","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:14:55.6847Z","iopub.execute_input":"2021-09-29T10:14:55.687075Z","iopub.status.idle":"2021-09-29T10:14:55.695909Z","shell.execute_reply.started":"2021-09-29T10:14:55.68704Z","shell.execute_reply":"2021-09-29T10:14:55.695136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataset(images):\n    x = tf.data.Dataset.from_tensor_slices(images).map(\n        create_noisy_image, num_parallel_calls=tf.data.experimental.AUTOTUNE\n    )\n    y = tf.data.Dataset.from_tensor_slices(images).map(\n        create_clean_image, num_parallel_calls=tf.data.experimental.AUTOTUNE\n    )\n    dataset = tf.data.Dataset.zip((x, y))\n    dataset = dataset.batch(batch_size).shuffle(shuffle_size).prefetch(tf.data.experimental.AUTOTUNE)\n\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:14:55.700234Z","iopub.execute_input":"2021-09-29T10:14:55.702387Z","iopub.status.idle":"2021-09-29T10:14:55.710614Z","shell.execute_reply.started":"2021-09-29T10:14:55.702354Z","shell.execute_reply":"2021-09-29T10:14:55.7098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Convolutional_block(Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.conv_1 = Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same')\n        self.conv_2 = Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same')\n        self.conv_3 = Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same')\n        self.conv_4 = Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same')\n\n    def call(self, X):\n        X_1 = self.conv_1(X)\n        X_1 = Activation('relu')(X_1)\n\n        X_2 = self.conv_2(X_1)\n        X_2 = Activation('relu')(X_2)\n\n        X_3 = self.conv_3(X_2)\n        X_3 = Activation('relu')(X_3)\n\n        X_4 = self.conv_4(X_3)\n        X_4 = Activation('relu')(X_4)\n        \n        #print('---conv block=',X_4.shape)\n        \n        return X_4\n    \nclass Channel_attention(Layer):\n    def __init__(self, C=64, **kwargs):\n        super().__init__(**kwargs)\n        self.C=C\n        self.gap = GlobalAveragePooling2D()\n        self.dense_middle = Dense(units=2, activation='relu')\n        self.dense_sigmoid = Dense(units=self.C, activation='sigmoid')\n    \n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'C': self.C\n        })\n        return config\n\n    def call(self, X):\n        v = self.gap(X)\n        #print(\"ca_ after gap =\",v.shape)\n        fc1 = self.dense_middle(v)\n        #print(\"ca_ after fc1 =\",fc1.shape)\n        mu = self.dense_sigmoid(fc1)\n        #print(\"ca_ after fc2 =\",mu.shape)\n\n        U_out = Multiply()([X, mu])\n        \n        #print('---channel attention block=',U_out.shape)\n\n        return U_out\n    \nclass Avg_pool_Unet_Upsample_msfe(Layer):\n    def __init__(self, avg_pool_size, upsample_rate, **kwargs):\n        super().__init__(**kwargs)\n        self.avg_pool_size=avg_pool_size\n        self.upsample_rate=upsample_rate\n        # ---initialization for Avg pooling---\n        self.avg_pool = AveragePooling2D(pool_size=avg_pool_size, padding='same')\n\n        # --- initialization for Unet---\n        self.deconv_lst = []\n        filter=512\n        for i in range(4):\n            self.deconv_lst.append(Conv2DTranspose(filters=filter/2, kernel_size=[3, 3], strides=2, padding='same'))\n            filter/=2\n\n        self.conv_32_down_lst = []\n        for i in range(2):\n            self.conv_32_down_lst.append(Conv2D(filters=64, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2=0.001)))\n\n        self.conv_64_down_lst = []\n        for i in range(2):\n            self.conv_64_down_lst.append(Conv2D(filters=128, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2=0.001)))\n\n        self.conv_128_down_lst = []\n        for i in range(2):\n            self.conv_128_down_lst.append(Conv2D(filters=256, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2=0.001)))\n\n        self.conv_256_down_lst = []\n        for i in range(2):\n            self.conv_256_down_lst.append(Conv2D(filters=512, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2=0.001)))\n\n        self.conv_512_down_lst = []\n        for i in range(2):\n            self.conv_512_down_lst.append(Conv2D(filters=1024, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2=0.001)))\n\n\n        self.conv_32_up_lst = []\n        for i in range(2):\n            self.conv_32_up_lst.append(Conv2D(filters=64, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2=0.001)))\n\n        self.conv_64_up_lst = []\n        for i in range(2):\n            self.conv_64_up_lst.append(Conv2D(filters=128, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2=0.001)))\n\n        self.conv_128_up_lst = []\n        for i in range(2):\n            self.conv_128_up_lst.append(Conv2D(filters=256, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2=0.001)))\n\n        self.conv_256_up_lst = []\n        for i in range(2):\n            self.conv_256_up_lst.append(Conv2D(filters=512, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2=0.001)))\n\n\n        self.conv_3 = Conv2D(filters=3, kernel_size=[1, 1])\n\n        self.pooling1_unet = MaxPool2D(pool_size=[2, 2], padding='same')\n        self.pooling2_unet = MaxPool2D(pool_size=[2, 2], padding='same')\n        self.pooling3_unet = MaxPool2D(pool_size=[2, 2], padding='same')\n        self.pooling4_unet = MaxPool2D(pool_size=[2, 2], padding='same')\n\n        # ---initialization for Upsampling---\n        self.upsample = UpSampling2D(upsample_rate, interpolation='bilinear')\n    \n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'avg_pool_size': self.avg_pool_size,\n            'upsample_rate':self.upsample_rate\n        })\n        return config\n\n    def upsample_and_concat(self, x1, x2, i):\n        deconv = self.deconv_lst[i](x1)\n        deconv_output = Concatenate()([deconv, x2])\n        return deconv_output\n\n    def unet(self, input):\n        # ---Unet downsampling---\n        conv1 = input\n        for c_32 in self.conv_32_down_lst:\n            conv1 = c_32(conv1)\n        pool1 = self.pooling1_unet(conv1)\n\n        conv2 = pool1\n        for c_64 in self.conv_64_down_lst:\n            conv2 = c_64(conv2)\n        pool2 = self.pooling2_unet(conv2)\n\n        conv3 = pool2\n        for c_128 in self.conv_128_down_lst:\n            conv3 = c_128(conv3)\n        pool3 = self.pooling3_unet(conv3)\n\n        conv4 = pool3\n        for c_256 in self.conv_256_down_lst:\n            conv4 = c_256(conv4)\n        pool4 = self.pooling4_unet(conv4)\n\n        conv5 = pool4\n        for c_512 in self.conv_512_down_lst:\n            conv5 = c_512(conv5)\n\n        # ---Unet upsampling---\n        up6 = self.upsample_and_concat(conv5, conv4, 0)\n        conv6 = up6\n        for c_256 in self.conv_256_up_lst:\n            conv6 = c_256(conv6)\n\n        up7 = self.upsample_and_concat(conv6, conv3, 1)\n        conv7 = up7\n        for c_128 in self.conv_128_up_lst:\n            conv7 = c_128(conv7)\n\n        up8 = self.upsample_and_concat(conv7, conv2, 2)\n        conv8 = up8\n        for c_64 in self.conv_64_up_lst:\n            conv8 = c_64(conv8)\n\n        up9 = self.upsample_and_concat(conv8, conv1, 3)\n        conv9 = up9\n        for c_32 in self.conv_32_up_lst:\n            conv9 = c_32(conv9)\n\n        conv10 = self.conv_3(conv9)\n        return conv10\n\n    def call(self, X):\n        avg_pool = self.avg_pool(X)\n        #print(\"ap =\",avg_pool.shape)\n        unet = self.unet(avg_pool)\n        upsample = self.upsample(unet)\n        return upsample\n\n\nclass Multi_scale_feature_extraction(Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.msfe_16 = Avg_pool_Unet_Upsample_msfe(avg_pool_size=16, upsample_rate=16)\n        self.msfe_8 = Avg_pool_Unet_Upsample_msfe(avg_pool_size=8, upsample_rate=8)\n        #self.msfe_4 = Avg_pool_Unet_Upsample_msfe(avg_pool_size=4, upsample_rate=4)\n        self.msfe_2 = Avg_pool_Unet_Upsample_msfe(avg_pool_size=2, upsample_rate=2)\n        #self.msfe_1 = Avg_pool_Unet_Upsample_msfe(avg_pool_size=1, upsample_rate=1)\n\n    def call(self, X):\n        up_sample_16 = self.msfe_16(X)\n        up_sample_8 = self.msfe_8(X)\n        #up_sample_4 = self.msfe_4(X) #if I add it I should add it in the concatenate\n        up_sample_2 = self.msfe_2(X)\n        #up_sample_1 = self.msfe_1(X)\n        msfe_out = Concatenate()([X, up_sample_16, up_sample_8, up_sample_2]) #, up_sample_1])\n\n        #print('---Multi scale feature extraction block=',msfe_out.shape)\n        return msfe_out\n    \nclass Kernel_selecting_module(Layer):\n    def __init__(self, C=21, **kwargs):\n        super().__init__(**kwargs)\n        self.C = C\n        self.c_3 = Conv2D(filters=self.C, kernel_size=(3,3), strides=1, padding='same', kernel_regularizer=regularizers.l2(l2=0.001))\n        self.c_5 = Conv2D(filters=self.C, kernel_size=(5,5), strides=1, padding='same', kernel_regularizer=regularizers.l2(l2=0.001))\n        self.c_7 = Conv2D(filters=self.C, kernel_size=(7,7), strides=1, padding='same', kernel_regularizer=regularizers.l2(l2=0.001))\n        self.gap = GlobalAveragePooling2D()\n        self.dense_two = Dense(units=2, activation='relu')\n        self.dense_c1 = Dense(units=self.C)\n        self.dense_c2 = Dense(units=self.C)\n        self.dense_c3 = Dense(units=self.C)\n    \n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'C': self.C\n        })\n        return config\n\n    def call(self, X):\n        X_1 = self.c_3(X)\n        X_2 = self.c_5(X)\n        X_3 = self.c_7(X)\n\n        X_dash = Add()([X_1, X_2, X_3])\n\n        v_gap = self.gap(X_dash)\n        v_gap = tf.reshape(v_gap, [-1, 1, 1, self.C])\n        fc1 = self.dense_two(v_gap)\n\n        alpha = self.dense_c1(fc1)\n        beta = self.dense_c2(fc1)\n        gamma = self.dense_c3(fc1)\n\n        before_softmax = concatenate([alpha, beta, gamma], 1)\n        # print(before_softmax.shape)\n        after_softmax = softmax(before_softmax, axis=1)\n        a1 = after_softmax[:, 0, :, :]\n        # print(a1)\n        a1 = tf.reshape(a1, [-1, 1, 1, self.C])\n        # print(a1)\n        a2 = after_softmax[:, 1, :, :]\n        a2 = tf.reshape(a2, [-1, 1, 1, self.C])\n        a3 = after_softmax[:, 2, :, :]\n        a3 = tf.reshape(a3, [-1, 1, 1, self.C])\n\n        select_1 = Multiply()([X_1, a1])\n        select_2 = Multiply()([X_2, a2])\n        select_3 = Multiply()([X_3, a3])\n\n        out = Add()([select_1, select_2, select_3])\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:20:18.724076Z","iopub.execute_input":"2021-09-29T10:20:18.724439Z","iopub.status.idle":"2021-09-29T10:20:18.77947Z","shell.execute_reply.started":"2021-09-29T10:20:18.724402Z","shell.execute_reply":"2021-09-29T10:20:18.778667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_autoencoder():\n    inputs = Input(shape=(*img_size, 3), name=\"dirty_image\")\n    conv_block = Convolutional_block()(inputs)\n    ca_block = Channel_attention()(conv_block)\n    ca_block = Conv2D(filters=3, kernel_size=(3,3), strides=1, padding='same')(ca_block)\n    ca_block = Concatenate()([inputs, ca_block])\n\n    msfe_block = Multi_scale_feature_extraction()(ca_block)\n\n    ksm = Kernel_selecting_module()(msfe_block)\n    ksm = Conv2D(filters=3, kernel_size=(3,3), strides=1, padding='same', name=\"clean_image\")(ksm)\n    model = Model(inputs=[inputs], outputs=[ksm])\n    return model\n\nmodel = get_autoencoder()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:20:10.38234Z","iopub.execute_input":"2021-09-29T10:20:10.382618Z","iopub.status.idle":"2021-09-29T10:20:12.006609Z","shell.execute_reply.started":"2021-09-29T10:20:10.382583Z","shell.execute_reply":"2021-09-29T10:20:12.005866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def PSNR(y_true, y_pred):\n    return tf.image.psnr(y_true, y_pred, 1)\n\ndef SSIM(y_true, y_pred):\n    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1))","metadata":{"execution":{"iopub.status.busy":"2021-09-22T15:44:22.246865Z","iopub.execute_input":"2021-09-22T15:44:22.247723Z","iopub.status.idle":"2021-09-22T15:44:22.252861Z","shell.execute_reply.started":"2021-09-22T15:44:22.247677Z","shell.execute_reply":"2021-09-22T15:44:22.252047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    train_dataset, valid_dataset, test_dataset = preprocess_data()\n\n    if use_small_dataset:\n        filepath = \"model\"\n        partial_filepath = \"partial_model\"\n    else:\n        filepath = \"model_large\"\n        partial_filepath = \"partial_model_large\"\n\n    if not train_from_zero and os.path.isdir(\"/kaggle/working/\" + filepath):\n        autoencoder = load_model(filepath)\n    else:\n        checkpoint = ModelCheckpoint(partial_filepath, save_best_only=True)\n        reduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=1e-5, verbose=1)\n        early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n\n        # we check if the model has any checkpoint\n        if not train_from_zero and os.path.isdir(\"/kaggle/working/\" + partial_filepath):\n            path = partial_filepath\n            autoencoder = load_model(partial_filepath)\n\n            nb_epochs = epochs\n        else:\n            path = filepath\n            autoencoder = get_autoencoder()\n            autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n            autoencoder.summary()\n            plot_model(\n                autoencoder, to_file='model_architecture.png', show_shapes=True, show_dtype=False,\n                show_layer_names=True, rankdir='TB', expand_nested=True, dpi=200\n            )\n            nb_epochs = epochs\n\n        then = time.time()\n\n        history = autoencoder.fit(\n            train_dataset,\n            epochs=epochs,\n            validation_data=valid_dataset,\n            callbacks=[early_stopping, checkpoint, reduce]\n        )\n        print(f\"Training finished for {nb_epochs} epochs after {time.time() - then} seconds\")\n        autoencoder.save(path)\n\n        dirty_input, clean_output = test_dataset\n        then = time.time()\n        prediction = autoencoder.predict(dirty_input)\n        print(f\"Inference finished after {time.time() - then} seconds\")\n\n        show_history(history)\n\n        then = time.time()\n        eval = autoencoder.evaluate(dirty_input, clean_output)\n        print(f\"Evaluation finished after {time.time() - then} seconds\")\n        #print(f\"The result of evaluation is: Loss: {eval[0]}, MSE: {eval[1]}\")\n        print(f\"The result of evaluation is: Loss: {eval}\")\n        \n        display(dirty_input, clean_output, prediction)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:20:46.724291Z","iopub.execute_input":"2021-09-29T10:20:46.724635Z","iopub.status.idle":"2021-09-29T10:20:46.735855Z","shell.execute_reply.started":"2021-09-29T10:20:46.724595Z","shell.execute_reply":"2021-09-29T10:20:46.734965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_history(history):\n\n    # retrieve all the indicators of the evolution of the training\n    # loss,...\n\n    indicators = list(history.history.keys())\n\n    # we only need the first half because the second is just the validation metrics\n\n    indicators = indicators[:len(indicators)//2]\n\n    for focus in indicators:\n        # Defining Figure\n        f = plt.figure(figsize=(10, 7))\n        f.add_subplot()\n\n        # Adding Subplot\n        plt.plot(history.epoch, history.history[focus], label=focus)\n        plt.plot(history.epoch, history.history[f'val_{focus}'], label=f\"val_{focus}\")\n\n        plt.title(f\"{focus} Curve\", fontsize=18)\n        plt.xlabel(\"Epochs\", fontsize=15)\n        plt.ylabel(focus, fontsize=15)\n        plt.grid(alpha=0.3)\n        plt.legend()\n        plt.savefig(f\"{focus}_curve.png\")\n        # plt.show()\n        plt.close()\n\n\ndef display(noisy_img, clean_img, predicted_img):\n    pathlib.Path('imgs').mkdir(parents=True, exist_ok=True)\n\n    clean_img = tf.cast(tf.multiply(clean_img, 255.0), dtype=tf.int32)\n    noisy_img = tf.cast(tf.multiply(noisy_img, 255.0), dtype=tf.int32)\n    predicted_img = tf.cast(tf.multiply(predicted_img, 255.0), dtype=tf.int32)\n\n    indices = np.random.randint(len(clean_img), size=nb_imgs_displayed*nb_pages)\n    indices = indices.reshape((nb_pages, nb_imgs_displayed))\n\n    row_titles = [\"original\\n\", \"dirty\\n\", \"predicted\\n\"]\n\n    for page in range(nb_pages):\n        print(\"Plot\")\n        index = 0\n        noisy = []\n        clean = []\n        predicted = []\n        for i in indices[page]:\n            clean.append(clean_img[i])\n            noisy.append(noisy_img[i])\n            predicted.append(predicted_img[i])\n\n        images = [clean, noisy, predicted]\n        fig = plt.figure(figsize=(10, 6))\n        # create 3x1 subfigs\n        subfigs = fig.subfigures(nrows=3, ncols=1)\n\n        for row, subfig in enumerate(subfigs):\n            subfig.suptitle(row_titles[row-1])\n            col_index = index\n            # create 1x3 subplots per subfig\n            axs = subfig.subplots(nrows=1, ncols=nb_imgs_displayed)\n            for col, ax in enumerate(axs):\n                ax.imshow(images[row-1][col_index])\n                col_index += 1\n                ax.get_xaxis().set_visible(False)\n                ax.get_yaxis().set_visible(False)\n\n        index += nb_imgs_displayed\n\n        plt.savefig(f\"imgs/{int(round(datetime.now().timestamp()))}.png\", dpi=200)\n        plt.show()\n        plt.close()","metadata":{"_uuid":"1b8da916-c650-484f-904c-29bb0b1681ca","_cell_guid":"58315d57-f263-44a1-95d5-70ff5a211dd0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-29T10:21:18.006385Z","iopub.execute_input":"2021-09-29T10:21:18.006742Z","iopub.status.idle":"2021-09-29T10:21:18.025003Z","shell.execute_reply.started":"2021-09-29T10:21:18.006707Z","shell.execute_reply":"2021-09-29T10:21:18.024218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:21:19.862583Z","iopub.execute_input":"2021-09-29T10:21:19.863443Z","iopub.status.idle":"2021-09-29T10:25:32.829578Z","shell.execute_reply.started":"2021-09-29T10:21:19.863395Z","shell.execute_reply":"2021-09-29T10:25:32.824144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}